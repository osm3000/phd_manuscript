\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{quickdraw}
\citation{ha2015mdntf}
\citation{howrnnworks}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Introduction and Problem Description}{15}{part.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{17}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}What is a style?}{17}{section.1.1}}
\newlabel{sec:style}{{1.1}{17}{What is a style?}{section.1.1}{}}
\newlabel{sec:style@cref}{{[section][1][1]1.1}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Why studying styles?}{17}{section.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Why Handwriting?}{18}{section.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}An overview of the PhD}{18}{section.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Disclaimer}{18}{section.1.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Datasets}{19}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Introduction}{19}{section.2.1}}
\citation{791823}
\citation{marti1999full}
\zref@newlabel{mdf@pagelabel-1}{\default{2.1}\page{20}\abspage{20}\mdf@pagevalue{20}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Online Handwriting -- \textit  {IRONOFF}}{20}{section.2.2}}
\citation{quickdrawgame}
\citation{quickdraw}
\citation{quickdraw}
\citation{quickdraw}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Sketch Drawing -- \textit  {QuickDraw!}}{21}{section.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces An example from \textit  {IRONOFF} (letter 'a'). To the left, we have the image of the letter (i.e., offline-handwriting). To the right is an example of the format for the online-handwriting. We have the writer's ID, origin, handiness, age and gender. The sequence of pen movement to draw the letter are then given: pen state (PEN\_DOWN, PEN\_UP), X, Y coordinates, pen pressure, and time.\relax }}{22}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:ironoff_example}{{2.1}{22}{An example from \textit {IRONOFF} (letter 'a'). To the left, we have the image of the letter (i.e., offline-handwriting). To the right is an example of the format for the online-handwriting. We have the writer's ID, origin, handiness, age and gender. The sequence of pen movement to draw the letter are then given: pen state (PEN\_DOWN, PEN\_UP), X, Y coordinates, pen pressure, and time.\relax }{figure.caption.4}{}}
\newlabel{fig:ironoff_example@cref}{{[figure][1][2]2.1}{22}}
\newlabel{RF1}{23}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Summary statistics about the writers in \textit  {IRONOFF}: the age, gender, country and handiness.\relax }}{23}{figure.caption.5}}
\newlabel{fig:ironoff_basic_stats}{{2.2}{23}{Summary statistics about the writers in \textit {IRONOFF}: the age, gender, country and handiness.\relax }{figure.caption.5}{}}
\newlabel{fig:ironoff_basic_stats@cref}{{[figure][2][2]2.2}{23}}
\newlabel{RF2}{24}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Summary statistics strokes for all categories in \textit  {IRONOFF} dataset (uppercase and lowercase letters, and digits), starting from the simplest to the more complex.\relax }}{24}{figure.caption.6}}
\newlabel{fig:ironoff_strokes}{{2.3}{24}{Summary statistics strokes for all categories in \textit {IRONOFF} dataset (uppercase and lowercase letters, and digits), starting from the simplest to the more complex.\relax }{figure.caption.6}{}}
\newlabel{fig:ironoff_strokes@cref}{{[figure][3][2]2.3}{24}}
\newlabel{RF3}{25}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Drawing time for all categories in \textit  {IRONOFF} dataset, arranged from the smallest to the largest.\relax }}{25}{figure.caption.7}}
\newlabel{fig:ironoff_drawingtime}{{2.4}{25}{Drawing time for all categories in \textit {IRONOFF} dataset, arranged from the smallest to the largest.\relax }{figure.caption.7}{}}
\newlabel{fig:ironoff_drawingtime@cref}{{[figure][4][2]2.4}{25}}
\newlabel{RF4}{26}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Pausing time for all categories in \textit  {IRONOFF} dataset, arranged from the smallest to the largest.\relax }}{26}{figure.caption.8}}
\newlabel{fig:ironoff_pausingtime}{{2.5}{26}{Pausing time for all categories in \textit {IRONOFF} dataset, arranged from the smallest to the largest.\relax }{figure.caption.8}{}}
\newlabel{fig:ironoff_pausingtime@cref}{{[figure][5][2]2.5}{26}}
\newlabel{RF5}{27}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Examples from different categories in \textit  {QuickDraw!} dataset. Source of the images are \citep  {quickdraw}\relax }}{27}{figure.caption.9}}
\newlabel{fig:quickdraw_preview}{{2.6}{27}{Examples from different categories in \textit {QuickDraw!} dataset. Source of the images are \citep {quickdraw}\relax }{figure.caption.9}{}}
\newlabel{fig:quickdraw_preview@cref}{{[figure][6][2]2.6}{27}}
\citation{seraphin2019analyzing}
\citation{ha2017neural}
\citation{goodfellow2014generative}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Data representation}{30}{section.2.4}}
\newlabel{sec:data_representation}{{2.4}{30}{Data representation}{section.2.4}{}}
\newlabel{sec:data_representation@cref}{{[section][4][2]2.4}{30}}
\newlabel{RF6}{31}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces The distribution of the strokes in \textit  {QuickDraw!} for the recognized shapes, for each category.\relax }}{31}{figure.caption.10}}
\newlabel{fig:recognition}{{2.7}{31}{The distribution of the strokes in \textit {QuickDraw!} for the recognized shapes, for each category.\relax }{figure.caption.10}{}}
\newlabel{fig:recognition@cref}{{[figure][7][2]2.7}{31}}
\newlabel{RF7}{32}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces The recognized VS non-recognized drawings in \textit  {QuickDraw!} in each of the selected categories.\relax }}{32}{figure.caption.11}}
\newlabel{fig:stroke_count}{{2.8}{32}{The recognized VS non-recognized drawings in \textit {QuickDraw!} in each of the selected categories.\relax }{figure.caption.11}{}}
\newlabel{fig:stroke_count@cref}{{[figure][8][2]2.8}{32}}
\newlabel{RF8}{33}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces QuickDraw! strokes statistics for each of the selected categories.\relax }}{33}{figure.caption.12}}
\newlabel{fig:quickdraw_strokes}{{2.9}{33}{QuickDraw! strokes statistics for each of the selected categories.\relax }{figure.caption.12}{}}
\newlabel{fig:quickdraw_strokes@cref}{{[figure][9][2]2.9}{33}}
\newlabel{RF9}{34}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces QuickDraw! pausing time statistics for each of the selected categories.\relax }}{34}{figure.caption.13}}
\newlabel{fig:quickdraw_pausing_time}{{2.10}{34}{QuickDraw! pausing time statistics for each of the selected categories.\relax }{figure.caption.13}{}}
\newlabel{fig:quickdraw_pausing_time@cref}{{[figure][10][2]2.10}{34}}
\newlabel{RF10}{35}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces QuickDraw! drawing time statistics for each of the selected categories.\relax }}{35}{figure.caption.14}}
\newlabel{fig:quickdraw_drawing_time}{{2.11}{35}{QuickDraw! drawing time statistics for each of the selected categories.\relax }{figure.caption.14}{}}
\newlabel{fig:quickdraw_drawing_time@cref}{{[figure][11][2]2.11}{35}}
\newlabel{RF11}{36}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces The most dominant countries for the players in QuickDraw! dataset. In the sample we analyzed, there is players from around 160 countries, but the majorty are from United States, followed by Great Britain.\relax }}{36}{figure.caption.15}}
\newlabel{fig:quickdraw_countries}{{2.12}{36}{The most dominant countries for the players in QuickDraw! dataset. In the sample we analyzed, there is players from around 160 countries, but the majorty are from United States, followed by Great Britain.\relax }{figure.caption.15}{}}
\newlabel{fig:quickdraw_countries@cref}{{[figure][12][2]2.12}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Continuous or Discrete representation?}{37}{subsection.2.4.1}}
\citation{bishop1994mixture}
\citation{Murphy:2012:MLP:2380985}
\@writefile{toc}{\contentsline {paragraph}{Continuous Data Representation}{38}{section*.16}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Example of a single-hidden layer neural network. The circle units is the sum of the weighted neurons connected to this unit, and the square units is the application of the activation function on that sum.\relax }}{38}{figure.caption.17}}
\newlabel{fig:mlp_simple}{{2.13}{38}{Example of a single-hidden layer neural network. The circle units is the sum of the weighted neurons connected to this unit, and the square units is the application of the activation function on that sum.\relax }{figure.caption.17}{}}
\newlabel{fig:mlp_simple@cref}{{[figure][13][2]2.13}{38}}
\citation{ha2015mdntf}
\citation{ha2015mdntf}
\citation{graves2013generating}
\citation{zen2014deep,wang2016gating,Wang2017AnAR}
\citation{graves2013generating}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces The performance of the simple linear activation function on two setups. Left: in case of one-to-one mapping between the input and the output, it performs well. Right: In case of one-to-many mapping, the function starts to average over the seen observations, leading to undesirable behaviour. Source of this image is \citep  {ha2015mdntf}.\relax }}{39}{figure.caption.18}}
\newlabel{fig:linear_activation_issue}{{2.14}{39}{The performance of the simple linear activation function on two setups. Left: in case of one-to-one mapping between the input and the output, it performs well. Right: In case of one-to-many mapping, the function starts to average over the seen observations, leading to undesirable behaviour. Source of this image is \citep {ha2015mdntf}.\relax }{figure.caption.18}{}}
\newlabel{fig:linear_activation_issue@cref}{{[figure][14][2]2.14}{39}}
\@writefile{toc}{\contentsline {paragraph}{Discrete Data Representation}{39}{section*.19}}
\citation{oord2016pixel,oord2016wavenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Feature engineering: Direction and Speed}{40}{subsection.2.4.2}}
\citation{freeman1961encoding}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Summary}{41}{section.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.15}{\ignorespaces Example for freeman code representation for 8 directions. Each direction is given a unique number.\relax }}{42}{figure.caption.20}}
\newlabel{fig:freeman_dir}{{2.15}{42}{Example for freeman code representation for 8 directions. Each direction is given a unique number.\relax }{figure.caption.20}{}}
\newlabel{fig:freeman_dir@cref}{{[figure][15][2]2.15}{42}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Experiments}{45}{part.2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Generation, benchmarks and evaluation}{47}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:GBEM}{{3}{47}{Generation, benchmarks and evaluation}{chapter.3}{}}
\newlabel{ch:GBEM@cref}{{[chapter][3][]3}{47}}
\citation{lecun2015deep,Goodfellow-et-al-2016}
\citation{krizhevsky2012imagenet,simonyan2014very,he2016deep}
\citation{oord2016wavenet}
\citation{DBLP:journals/corr/VinyalsTBE14,karpathy2015deep}
\citation{sutskever2014sequence}
\citation{silver2016mastering}
\citation{lowe1999object}
\citation{narang2015speech}
\zref@newlabel{mdf@pagelabel-2}{\default{3}\page{48}\abspage{48}\mdf@pagevalue{48}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Background}{48}{section.3.1}}
\newlabel{sec:gbem_background}{{3.1}{48}{Background}{section.3.1}{}}
\newlabel{sec:gbem_background@cref}{{[section][1][3]3.1}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Deep Learning: quick overview}{48}{subsection.3.1.1}}
\citation{Goodfellow-et-al-2016}
\citation{chollet2017book,geron2017hands}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}A word about sequential data}{49}{subsection.3.1.2}}
\newlabel{sec:seq_data}{{3.1.2}{49}{A word about sequential data}{subsection.3.1.2}{}}
\newlabel{sec:seq_data@cref}{{[subsection][2][3,1]3.1.2}{49}}
\newlabel{eq:rnn_obj_training_0}{{3.1}{49}{A word about sequential data}{equation.3.1.1}{}}
\newlabel{eq:rnn_obj_training_0@cref}{{[equation][1][3]3.1}{49}}
\citation{oord2016wavenet,gehring2017convolutional}
\citation{howrnnworks}
\citation{howrnnworks}
\newlabel{eq:rnn_factorization}{{3.2}{50}{A word about sequential data}{equation.3.1.2}{}}
\newlabel{eq:rnn_factorization@cref}{{[equation][2][3]3.2}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Recurrent Neural Networks and Sequence Generation}{50}{subsection.3.1.3}}
\newlabel{sec:RNN}{{3.1.3}{50}{Recurrent Neural Networks and Sequence Generation}{subsection.3.1.3}{}}
\newlabel{sec:RNN@cref}{{[subsection][3][3,1]3.1.3}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces A demonstration of how RNN works: the network is applied on each token in the input ($x_1, x_2, ..., x_t$), while update the hidden state variable every time ($h_0, h_1, ..., h_t$). The output at each step is a function of the hidden state variable (not demonstrated here). Source of the image is (\citep  {howrnnworks}).\relax }}{51}{figure.caption.22}}
\newlabel{fig:basic_rnn_model}{{3.1}{51}{A demonstration of how RNN works: the network is applied on each token in the input ($x_1, x_2, ..., x_t$), while update the hidden state variable every time ($h_0, h_1, ..., h_t$). The output at each step is a function of the hidden state variable (not demonstrated here). Source of the image is (\citep {howrnnworks}).\relax }{figure.caption.22}{}}
\newlabel{fig:basic_rnn_model@cref}{{[figure][1][3]3.1}{51}}
\newlabel{eq:rnn_equations}{{3.3}{51}{Recurrent Neural Networks and Sequence Generation}{equation.3.1.3}{}}
\newlabel{eq:rnn_equations@cref}{{[equation][3][3]3.3}{51}}
\citation{gradientdescent}
\citation{convexfn}
\newlabel{eq:loss_fn_mse}{{3.4}{52}{Recurrent Neural Networks and Sequence Generation}{equation.3.1.4}{}}
\newlabel{eq:loss_fn_mse@cref}{{[equation][4][3]3.4}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}Optimization Algorithms}{52}{subsection.3.1.4}}
\newlabel{subsec:optimization}{{3.1.4}{52}{Optimization Algorithms}{subsection.3.1.4}{}}
\newlabel{subsec:optimization@cref}{{[subsection][4][3,1]3.1.4}{52}}
\newlabel{eq:grad_descent}{{3.5}{52}{Optimization Algorithms}{equation.3.1.5}{}}
\newlabel{eq:grad_descent@cref}{{[equation][5][3]3.5}{52}}
\citation{Goodfellow-et-al-2016}
\citation{Goodfellow-et-al-2016}
\citation{lecture_nn_optimization}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces A demonstration for how a gradient descent algorithm work. The optimization process progress each step towards the global optima (the indicated point in the center).\relax }}{53}{figure.caption.23}}
\newlabel{fig:grad_descent}{{3.2}{53}{A demonstration for how a gradient descent algorithm work. The optimization process progress each step towards the global optima (the indicated point in the center).\relax }{figure.caption.23}{}}
\newlabel{fig:grad_descent@cref}{{[figure][2][3]3.2}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The process of gradient descent is iterative, and include 3 steps: evaluate the quality of the current parameters (forward-pass step), get the error value, use the error-value in order to update the parameters/getting new set of parameters (back-propagation step). This process is repeated N times, which is decided by either not observing any update in the error, or we ran out of computational resources.\relax }}{54}{figure.caption.24}}
\newlabel{fig:grad_descent_inuitive}{{3.3}{54}{The process of gradient descent is iterative, and include 3 steps: evaluate the quality of the current parameters (forward-pass step), get the error value, use the error-value in order to update the parameters/getting new set of parameters (back-propagation step). This process is repeated N times, which is decided by either not observing any update in the error, or we ran out of computational resources.\relax }{figure.caption.24}{}}
\newlabel{fig:grad_descent_inuitive@cref}{{[figure][3][3]3.3}{54}}
\citation{robbins1951stochastic}
\citation{rumelhart1988learning}
\citation{hinton2012neural}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsubsection}{Mini-batch optimization}{55}{section*.25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}Architectures}{56}{subsection.3.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.6}Inference: How to generate sequences from the network?}{56}{subsection.3.1.6}}
\citation{chollet2017book}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces An example of using RNN in order to infer a sentence. The token to be generated here is a character. At each time step, the model is given the part of the sentence that has been generated so far, and asked to give the probability distribution over the next character. This distribution is then given to the selected sampling distribution, which sample the next character, and so on.\relax }}{57}{figure.caption.26}}
\newlabel{fig:text_gen}{{3.4}{57}{An example of using RNN in order to infer a sentence. The token to be generated here is a character. At each time step, the model is given the part of the sentence that has been generated so far, and asked to give the probability distribution over the next character. This distribution is then given to the selected sampling distribution, which sample the next character, and so on.\relax }{figure.caption.26}{}}
\newlabel{fig:text_gen@cref}{{[figure][4][3]3.4}{57}}
\newlabel{eq:rnn_obj_inf}{{3.6}{57}{Inference: How to generate sequences from the network?}{equation.3.1.6}{}}
\newlabel{eq:rnn_obj_inf@cref}{{[equation][6][3]3.6}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.7}How to introduce prior to the model? (conditioning the model)}{58}{subsection.3.1.7}}
\newlabel{RF12}{59}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Illustration of temperature sampling. When the temperature $\tau $ is very low, it becomes greedy sampling. With the increase of temperature, we can see more higher possibility of sampling the lower-probability tokens. When the temperature is too high, it becomes uniform sampling.\relax }}{59}{figure.caption.27}}
\newlabel{fig:temperature_sampling}{{3.5}{59}{Illustration of temperature sampling. When the temperature $\tau $ is very low, it becomes greedy sampling. With the increase of temperature, we can see more higher possibility of sampling the lower-probability tokens. When the temperature is too high, it becomes uniform sampling.\relax }{figure.caption.27}{}}
\newlabel{fig:temperature_sampling@cref}{{[figure][5][3]3.5}{59}}
\citation{karpathy2015deep}
\citation{vinyals2015show}
\citation{ha2017neural}
\@writefile{toc}{\contentsline {paragraph}{Initialize the first hidden state directly}{60}{section*.28}}
\@writefile{toc}{\contentsline {paragraph}{Using the first time-step}{60}{section*.29}}
\@writefile{toc}{\contentsline {paragraph}{Using context sequence -- multiple time-steps --}{60}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{Concatenating input time-steps with the condition}{60}{section*.31}}
\citation{NIPS2010_4089,denil2012learning}
\citation{xu2015show}
\citation{wang2017tacotron}
\@writefile{toc}{\contentsline {paragraph}{Concatenating the hidden state with the condition}{61}{section*.32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.8}How to evaluate the quality of generation?}{61}{subsection.3.1.8}}
\newlabel{sec:eval_metrics}{{3.1.8}{61}{How to evaluate the quality of generation?}{subsection.3.1.8}{}}
\newlabel{sec:eval_metrics@cref}{{[subsection][8][3,1]3.1.8}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Putting all of that together}{61}{section.3.2}}
\newlabel{subfig:first_timestep}{{3.61}{62}{Initializing using the first time-step\relax }{figure.caption.33}{}}
\newlabel{subfig:first_timestep@cref}{{[subfigure][1][3,6]3.61}{62}}
\newlabel{sub@subfig:first_timestep}{{1}{62}{Initializing using the first time-step\relax }{figure.caption.33}{}}
\newlabel{sub@subfig:first_timestep@cref}{{[subfigure][1][3,6]3.61}{62}}
\newlabel{subfig:hidden_state}{{3.62}{62}{Initializing the hidden state\relax }{figure.caption.33}{}}
\newlabel{subfig:hidden_state@cref}{{[subfigure][2][3,6]3.62}{62}}
\newlabel{sub@subfig:hidden_state}{{2}{62}{Initializing the hidden state\relax }{figure.caption.33}{}}
\newlabel{sub@subfig:hidden_state@cref}{{[subfigure][2][3,6]3.62}{62}}
\newlabel{subfig:cat_timestep}{{3.63}{62}{Concatenating the condition with time-step\relax }{figure.caption.33}{}}
\newlabel{subfig:cat_timestep@cref}{{[subfigure][3][3,6]3.63}{62}}
\newlabel{sub@subfig:cat_timestep}{{3}{62}{Concatenating the condition with time-step\relax }{figure.caption.33}{}}
\newlabel{sub@subfig:cat_timestep@cref}{{[subfigure][3][3,6]3.63}{62}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Different conditioning method for RNN\relax }}{62}{figure.caption.33}}
\newlabel{fig:conditioning_model}{{3.6}{62}{Different conditioning method for RNN\relax }{figure.caption.33}{}}
\newlabel{fig:conditioning_model@cref}{{[figure][6][3]3.6}{62}}
\citation{mohammed2018handwriting}
\citation{papineni2002bleu}
\citation{karpathy2015deep,vinyals2015show}
\citation{Sutskever:2014:SSL:2969033.2969173}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Our proposed evaluation metrics}{63}{subsection.3.2.1}}
\newlabel{subsec:eval_metrics}{{3.2.1}{63}{Our proposed evaluation metrics}{subsection.3.2.1}{}}
\newlabel{subsec:eval_metrics@cref}{{[subsection][1][3,2]3.2.1}{63}}
\@writefile{toc}{\contentsline {paragraph}{BLEU score}{63}{section*.34}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Using BLEU score of different sizes, we compare segments of variable length in the generated trace to the target trace.\relax }}{64}{figure.caption.35}}
\newlabel{fig:bleu_score}{{3.7}{64}{Using BLEU score of different sizes, we compare segments of variable length in the generated trace to the target trace.\relax }{figure.caption.35}{}}
\newlabel{fig:bleu_score@cref}{{[figure][7][3]3.7}{64}}
\@writefile{toc}{\contentsline {paragraph}{End of Sequence}{65}{section*.36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}How to ground the metrics?}{65}{subsection.3.2.2}}
\newlabel{subsec:ground_metrics}{{3.2.2}{65}{How to ground the metrics?}{subsection.3.2.2}{}}
\newlabel{subsec:ground_metrics@cref}{{[subsection][2][3,2]3.2.2}{65}}
\newlabel{eq:cardinal_power}{{3.9}{66}{How to ground the metrics?}{equation.3.2.9}{}}
\newlabel{eq:cardinal_power@cref}{{[equation][9][3]3.9}{66}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Left: architecture of the CNN letter classifier. Batch normalization is used after each convolution layer. The \textit  {Dense 1} layer is the embedding that is used to condition our generator. Right: the autoencoder architecture we used. The first \textit  {Dense 34} layer provides the latent space used to condition the generator.\relax }}{66}{figure.caption.37}}
\newlabel{fig:architectures}{{3.8}{66}{Left: architecture of the CNN letter classifier. Batch normalization is used after each convolution layer. The \textit {Dense 1} layer is the embedding that is used to condition our generator. Right: the autoencoder architecture we used. The first \textit {Dense 34} layer provides the latent space used to condition the generator.\relax }{figure.caption.37}{}}
\newlabel{fig:architectures@cref}{{[figure][8][3]3.8}{66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Model used}{66}{subsection.3.2.3}}
\newlabel{subfig:dtl_training}{{3.91}{67}{Training mode\relax }{figure.caption.38}{}}
\newlabel{subfig:dtl_training@cref}{{[subfigure][1][3,9]3.91}{67}}
\newlabel{sub@subfig:dtl_training}{{1}{67}{Training mode\relax }{figure.caption.38}{}}
\newlabel{sub@subfig:dtl_training@cref}{{[subfigure][1][3,9]3.91}{67}}
\newlabel{subfig:dtl_generation}{{3.92}{67}{Generation mode\relax }{figure.caption.38}{}}
\newlabel{subfig:dtl_generation@cref}{{[subfigure][2][3,9]3.92}{67}}
\newlabel{sub@subfig:dtl_generation}{{2}{67}{Generation mode\relax }{figure.caption.38}{}}
\newlabel{sub@subfig:dtl_generation@cref}{{[subfigure][2][3,9]3.92}{67}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.9}{\ignorespaces The conditioned-GRU model used in this work. During the training mode \ref  {subfig:dtl_training}, the input of the model is always the ground truth, and the predicted value is compared to the ground truth. During the generation mode \ref  {subfig:dtl_generation}, the input to the model at each step is the model prediction from the previous step. The 'style info' and the 'task info' inputs are separated here for demonstration (they could be mixed).\relax }}{67}{figure.caption.38}}
\newlabel{fig:dtl_model}{{3.9}{67}{The conditioned-GRU model used in this work. During the training mode \ref {subfig:dtl_training}, the input of the model is always the ground truth, and the predicted value is compared to the ground truth. During the generation mode \ref {subfig:dtl_generation}, the input to the model at each step is the model prediction from the previous step. The 'style info' and the 'task info' inputs are separated here for demonstration (they could be mixed).\relax }{figure.caption.38}{}}
\newlabel{fig:dtl_model@cref}{{[figure][9][3]3.9}{67}}
\citation{maaten2008visualizing}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Results}{68}{subsection.3.2.4}}
\@writefile{toc}{\contentsline {subsubsection}{BLEU score}{68}{section*.39}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparing different approaches for style extraction using clipped n-grams\relax }}{69}{table.caption.40}}
\newlabel{table:1}{{1}{69}{Comparing different approaches for style extraction using clipped n-grams\relax }{table.caption.40}{}}
\newlabel{table:1@cref}{{[table][1][3]1}{69}}
\@writefile{toc}{\contentsline {subsubsection}{Sequence length}{69}{section*.42}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Examples of the generated letters}{69}{subsection.3.2.5}}
\newlabel{RF13}{70}
\newlabel{fig:autoenc_latent}{{3.101}{70}{\relax }{figure.caption.41}{}}
\newlabel{fig:autoenc_latent@cref}{{[subfigure][1][3,10]3.101}{70}}
\newlabel{sub@fig:autoenc_latent}{{1}{70}{\relax }{figure.caption.41}{}}
\newlabel{sub@fig:autoenc_latent@cref}{{[subfigure][1][3,10]3.101}{70}}
\newlabel{fig:classifier_latent}{{3.102}{70}{\relax }{figure.caption.41}{}}
\newlabel{fig:classifier_latent@cref}{{[subfigure][2][3,10]3.102}{70}}
\newlabel{sub@fig:classifier_latent}{{2}{70}{\relax }{figure.caption.41}{}}
\newlabel{sub@fig:classifier_latent@cref}{{[subfigure][2][3,10]3.102}{70}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.10}{\ignorespaces a) In the the autoencoder latent space, there is no clear separation between letters; the encoding is based on the similarity of the images only. b) In the classifier embedding, there is a clear separation between the letters - with few exceptions -.\relax }}{70}{figure.caption.41}}
\citation{papineni2002bleu}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Pearson correlation coefficients and associated p-values for the EOS distributions of the different style biases.\relax }}{71}{table.caption.43}}
\newlabel{table:2}{{2}{71}{Pearson correlation coefficients and associated p-values for the EOS distributions of the different style biases.\relax }{table.caption.43}{}}
\newlabel{table:2@cref}{{[table][2][3]2}{71}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Summary}{71}{section.3.3}}
\newlabel{RF14}{72}
\@writefile{lof}{\contentsline {figure}{\numberline {3.11}{\ignorespaces Examples of original letters. The blue \textit  {x} mark is the starting point. These ones are generated using the letter + Writer bias. E and F are visually harder to recognize, since we do not model the pen pressure, otherwise, the rest of the letters are well recognizable.\relax }}{72}{figure.caption.44}}
\newlabel{fig:orig_letters_examples}{{3.11}{72}{Examples of original letters. The blue \textit {x} mark is the starting point. These ones are generated using the letter + Writer bias. E and F are visually harder to recognize, since we do not model the pen pressure, otherwise, the rest of the letters are well recognizable.\relax }{figure.caption.44}{}}
\newlabel{fig:orig_letters_examples@cref}{{[figure][11][3]3.11}{72}}
\newlabel{RF15}{73}
\@writefile{lof}{\contentsline {figure}{\numberline {3.12}{\ignorespaces Examples of generated letters. The blue \textit  {x} mark is the starting point. These ones are generated using the letter + Writer bias. The general quality of this quite acceptable.\relax }}{73}{figure.caption.45}}
\newlabel{fig:letters_examples_gbem}{{3.12}{73}{Examples of generated letters. The blue \textit {x} mark is the starting point. These ones are generated using the letter + Writer bias. The general quality of this quite acceptable.\relax }{figure.caption.45}{}}
\newlabel{fig:letters_examples_gbem@cref}{{[figure][12][3]3.12}{73}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Framework}{75}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\zref@newlabel{mdf@pagelabel-3}{\default{4}\page{75}\abspage{75}\mdf@pagevalue{75}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Background}{76}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Auto-encoders}{76}{subsection.4.1.1}}
\newlabel{sec:autoencoder}{{4.1.1}{76}{Auto-encoders}{subsection.4.1.1}{}}
\newlabel{sec:autoencoder@cref}{{[subsection][1][4,1]4.1.1}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Objectives}{76}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Static and Temporal auto-encoder}{76}{subsection.4.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Putting it all together}{76}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Letter generation with style preservation}{76}{subsection.4.2.1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces BLEU scores for different models for known writers.\relax }}{77}{table.caption.47}}
\newlabel{table:bleu_gen}{{1}{77}{BLEU scores for different models for known writers.\relax }{table.caption.47}{}}
\newlabel{table:bleu_gen@cref}{{[table][1][4]1}{77}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces BLEU scores for different models for style extraction for 30 new writers (style transfer).\relax }}{77}{table.caption.48}}
\newlabel{table:bleu_transfer}{{2}{77}{BLEU scores for different models for style extraction for 30 new writers (style transfer).\relax }{table.caption.48}{}}
\newlabel{table:bleu_transfer@cref}{{[table][2][4]2}{77}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Pearson correlation coefficients for the End-Of-Sequence (EoS) distributions for the different models on the normal gene ration scenario\relax }}{77}{table.caption.49}}
\newlabel{table:EoS_gen}{{3}{77}{Pearson correlation coefficients for the End-Of-Sequence (EoS) distributions for the different models on the normal gene ration scenario\relax }{table.caption.49}{}}
\newlabel{table:EoS_gen@cref}{{[table][3][4]3}{77}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Pearson correlation coefficients for the End-Of-Sequence (EoS) distributions for the different models on 30 new writers (style transfer).\relax }}{77}{table.caption.50}}
\newlabel{table:EoS_transfer}{{4}{77}{Pearson correlation coefficients for the End-Of-Sequence (EoS) distributions for the different models on 30 new writers (style transfer).\relax }{table.caption.50}{}}
\newlabel{table:EoS_transfer@cref}{{[table][4][4]4}{77}}
\citation{jolliffe2011principal}
\citation{maaten2008visualizing}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Style transfer}{78}{subsection.4.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Styles per letters}{78}{subsection.4.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Results of the manual annotation for the rotation of letter X drawings over the whole dataset. Almost half the writers drew X clockwise, the other half anti-clockwise. The undefined styles were unclear to determine.\relax }}{80}{figure.caption.51}}
\newlabel{fig:x_rotation}{{4.1}{80}{Results of the manual annotation for the rotation of letter X drawings over the whole dataset. Almost half the writers drew X clockwise, the other half anti-clockwise. The undefined styles were unclear to determine.\relax }{figure.caption.51}{}}
\newlabel{fig:x_rotation@cref}{{[figure][1][4]4.1}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Projection for latent space for letter X using PCA. The colors show the ground truth of the X rotation: blue is counter clockwise, orange is clockwise, and the few red points are undefined.\relax }}{80}{figure.caption.52}}
\newlabel{fig:x_bottleneck}{{4.2}{80}{Projection for latent space for letter X using PCA. The colors show the ground truth of the X rotation: blue is counter clockwise, orange is clockwise, and the few red points are undefined.\relax }{figure.caption.52}{}}
\newlabel{fig:x_bottleneck@cref}{{[figure][2][4]4.2}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Examples for writing of letter X. Starting point is marked with the blue mark. Each raw is randomly sampled from each cluster in the bottleneck. The clusters shows that almost half the writers draw the letter clockwise (first row, first cluster), and the other half draw it anti-clockwise (second row, second cluster).\relax }}{81}{figure.caption.53}}
\newlabel{fig:examples_x}{{4.3}{81}{Examples for writing of letter X. Starting point is marked with the blue mark. Each raw is randomly sampled from each cluster in the bottleneck. The clusters shows that almost half the writers draw the letter clockwise (first row, first cluster), and the other half draw it anti-clockwise (second row, second cluster).\relax }{figure.caption.53}{}}
\newlabel{fig:examples_x@cref}{{[figure][3][4]4.3}{81}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Projection for latent space for letter C using t-SNE. The cluster surrounded by the red circle has a clear interpretation, where writers have a cursive style.\relax }}{82}{figure.caption.54}}
\newlabel{fig:c_letter}{{4.4}{82}{Projection for latent space for letter C using t-SNE. The cluster surrounded by the red circle has a clear interpretation, where writers have a cursive style.\relax }{figure.caption.54}{}}
\newlabel{fig:c_letter@cref}{{[figure][4][4]4.4}{82}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Projection for latent space for letter A using PCA.\relax }}{83}{figure.caption.55}}
\newlabel{fig:a_bottleneck}{{4.5}{83}{Projection for latent space for letter A using PCA.\relax }{figure.caption.55}{}}
\newlabel{fig:a_bottleneck@cref}{{[figure][5][4]4.5}{83}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Examples for writing of letter C from the selected cluster (first row) versus the rest of the letter drawings (second row). Starting point is marked with the blue mark. The drawings from the selected cluster show people with Edwardian style of handwriting.\relax }}{84}{figure.caption.56}}
\newlabel{fig:examples_c}{{4.6}{84}{Examples for writing of letter C from the selected cluster (first row) versus the rest of the letter drawings (second row). Starting point is marked with the blue mark. The drawings from the selected cluster show people with Edwardian style of handwriting.\relax }{figure.caption.56}{}}
\newlabel{fig:examples_c@cref}{{[figure][6][4]4.6}{84}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Examples for writing of letter A from the selected clusters. Starting point is marked with the blue mark. Each row is from one cluster. The first row show people who start drawing the letter from the top, going down, and then continue the drawing of the letter. The second row show people who start drawing from down directly.\relax }}{85}{figure.caption.57}}
\newlabel{fig:examples_a}{{4.7}{85}{Examples for writing of letter A from the selected clusters. Starting point is marked with the blue mark. Each row is from one cluster. The first row show people who start drawing the letter from the top, going down, and then continue the drawing of the letter. The second row show people who start drawing from down directly.\relax }{figure.caption.57}{}}
\newlabel{fig:examples_a@cref}{{[figure][7][4]4.7}{85}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Projection for latent space for letter S using t-SNE. We manage to interpret the indicated cluster as the Edwardian style in drawing. The other two clusters (not indicated) did not show clear difference in the style, but this is an expected behavior from using the t-SNE algorithm, since it does not try to cluster styles as an objective.\relax }}{86}{figure.caption.58}}
\newlabel{fig:s_bottleneck}{{4.8}{86}{Projection for latent space for letter S using t-SNE. We manage to interpret the indicated cluster as the Edwardian style in drawing. The other two clusters (not indicated) did not show clear difference in the style, but this is an expected behavior from using the t-SNE algorithm, since it does not try to cluster styles as an objective.\relax }{figure.caption.58}{}}
\newlabel{fig:s_bottleneck@cref}{{[figure][8][4]4.8}{86}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Examples for writing of letter S from the selected cluster (first row) versus the other two clusters (second row). Starting point is marked with the blue mark. The drawings from the selected cluster is always Edwardian style.\relax }}{87}{figure.caption.59}}
\newlabel{fig:examples_s}{{4.9}{87}{Examples for writing of letter S from the selected cluster (first row) versus the other two clusters (second row). Starting point is marked with the blue mark. The drawings from the selected cluster is always Edwardian style.\relax }{figure.caption.59}{}}
\newlabel{fig:examples_s@cref}{{[figure][9][4]4.9}{87}}
\newlabel{RF16}{88}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Examples of generated letters. The blue mark is the starting point. The traces in green is the ground truth, and the red is the generated ones by our model.\relax }}{88}{figure.caption.60}}
\newlabel{fig:letters_examples}{{4.10}{88}{Examples of generated letters. The blue mark is the starting point. The traces in green is the ground truth, and the red is the generated ones by our model.\relax }{figure.caption.60}{}}
\newlabel{fig:letters_examples@cref}{{[figure][10][4]4.10}{88}}
\newlabel{RF17}{89}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Examples of generated letters. The blue mark is the starting point. The traces in green is the ground truth, and the red is the generated ones by our model.\relax }}{89}{figure.caption.61}}
\newlabel{fig:letters_examples_2}{{4.11}{89}{Examples of generated letters. The blue mark is the starting point. The traces in green is the ground truth, and the red is the generated ones by our model.\relax }{figure.caption.61}{}}
\newlabel{fig:letters_examples_2@cref}{{[figure][11][4]4.11}{89}}
\citation{papineni2002bleu}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Style Extraction and Transfer}{91}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction and objectives}{91}{section.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Transfer learning}{91}{section.5.2}}
\newlabel{sec:transfer_learning}{{5.2}{91}{Transfer learning}{section.5.2}{}}
\newlabel{sec:transfer_learning@cref}{{[section][2][5]5.2}{91}}
\citation{shimodaira2000improving,weiss2016survey}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Notation and problem definition}{92}{subsection.5.2.1}}
\citation{taylor2007cross}
\@writefile{toc}{\contentsline {paragraph}{Symmetric and Asymmetric transfer}{93}{section*.63}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Symmetric and Asymmetric transfer}}{93}{figure.caption.64}}
\newlabel{fig:feature_transformation}{{5.1}{93}{Symmetric and Asymmetric transfer}{figure.caption.64}{}}
\newlabel{fig:feature_transformation@cref}{{[figure][1][5]5.1}{93}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Metrics to evaluate transfer learning}{93}{subsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Different proposed metrics to measure transfer learning \textbf  {Mention the source of this image}\relax }}{94}{figure.caption.65}}
\newlabel{fig:tl_metrics}{{5.2}{94}{Different proposed metrics to measure transfer learning \textbf {Mention the source of this image}\relax }{figure.caption.65}{}}
\newlabel{fig:tl_metrics@cref}{{[figure][2][5]5.2}{94}}
\citation{glorot2011domain}
\citation{lecun2015deep}
\citation{raina2009large}
\citation{imagenet_cvpr09}
\citation{2014arXiv1405.0312L}
\citation{krizhevsky2012imagenet}
\citation{simonyan2014very}
\citation{szegedy2015going}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Homogeneous transfer learning}{95}{subsection.5.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{Symmetric - transfer learning using deep learning}{95}{section*.66}}
\citation{fogel1989gabor,jain1991unsupervised}
\citation{fogel1989gabor,jain1991unsupervised}
\citation{s16010115,pinheiro2014recurrent,huang2016deep}
\citation{chattopadhyay2012multisource}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Convolution Neural Networks filters shape}}{96}{figure.caption.67}}
\newlabel{fig:AlexNet_filters}{{5.3}{96}{Convolution Neural Networks filters shape}{figure.caption.67}{}}
\newlabel{fig:AlexNet_filters@cref}{{[figure][3][5]5.3}{96}}
\citation{chattopadhyay2012multisource}
\@writefile{toc}{\contentsline {subsubsection}{Parameter-based transfer}{97}{section*.68}}
\@writefile{toc}{\contentsline {subsubsection}{Instance-based transfer}{97}{section*.69}}
\citation{shi2010transfer}
\citation{Nam:2015:HDP:2786805.2786814}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Heterogeneous transfer learning}{98}{subsection.5.2.4}}
\@writefile{toc}{\contentsline {subsubsection}{Symmetric}{98}{section*.70}}
\@writefile{toc}{\contentsline {subsubsection}{Asymmetric}{98}{section*.71}}
\citation{taylor2008transferring,torrey2010transfer}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Negative transfer}{99}{subsection.5.2.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Application of transfer learning}{100}{section.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Transfer between writers}{100}{subsection.5.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Transfer between tasks}{100}{subsection.5.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Style Extraction}{100}{section.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Summary}{100}{section.5.5}}
\@writefile{toc}{\contentsline {part}{III\hspace  {1em}Discussion and Closing Remarks}{101}{part.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Discussion}{103}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Challenges}{103}{section.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Choice of the topic}{103}{subsection.6.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Unclear state-of-the art}{103}{subsection.6.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Lack of Benchmarks, evaluation metrics}{104}{subsection.6.1.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.4}Deep learning: theory, hardware and software frameworks}{104}{subsection.6.1.4}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Limitations of the current work}{104}{section.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Style extraction and exploration using PCA and tSNE methods}{104}{subsection.6.2.1}}
\@writefile{toc}{\contentsline {paragraph}{PCA}{105}{section*.73}}
\@writefile{toc}{\contentsline {paragraph}{tSNE}{105}{section*.74}}
\citation{hinton2015distilling}
\citation{lecun-mnisthandwrittendigit-2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Leak in the style module}{106}{subsection.6.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Future directions}{107}{section.6.3}}
\newlabel{sec:future_direction}{{6.3}{107}{Future directions}{section.6.3}{}}
\newlabel{sec:future_direction@cref}{{[section][3][6]6.3}{107}}
\citation{wagstaff2012machine}
\bibstyle{apalike}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Closing Remarks}{111}{chapter.7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{bishop1994mixture}{{1}{1994}{{Bishop}}{{}}}
\bibcite{chattopadhyay2012multisource}{{2}{2012}{{Chattopadhyay et~al.}}{{}}}
\bibcite{chollet2017book}{{3}{2017}{{Chollet}}{{}}}
\bibcite{lecture_nn_optimization}{{4}{2017}{{De~Sa}}{{}}}
\bibcite{imagenet_cvpr09}{{5}{2009}{{Deng et~al.}}{{}}}
\bibcite{denil2012learning}{{6}{2012}{{Denil et~al.}}{{}}}
\bibcite{fogel1989gabor}{{7}{1989}{{Fogel and Sagi}}{{}}}
\bibcite{freeman1961encoding}{{8}{1961}{{Freeman}}{{}}}
\bibcite{gehring2017convolutional}{{9}{2017}{{Gehring et~al.}}{{}}}
\bibcite{geron2017hands}{{10}{2017}{{G{\'e}ron}}{{}}}
\bibcite{glorot2011domain}{{11}{2011}{{Glorot et~al.}}{{}}}
\bibcite{Goodfellow-et-al-2016}{{12}{2016}{{Goodfellow et~al.}}{{}}}
\bibcite{goodfellow2014generative}{{13}{2014}{{Goodfellow et~al.}}{{}}}
\bibcite{quickdraw}{{14}{2017}{{Google}}{{}}}
\bibcite{graves2013generating}{{15}{2013}{{Graves}}{{}}}
\bibcite{ha2015mdntf}{{16}{2015}{{Ha}}{{}}}
\bibcite{ha2017neural}{{17}{2017}{{Ha and Eck}}{{}}}
\bibcite{he2016deep}{{18}{2016}{{He et~al.}}{{}}}
\bibcite{hinton2012neural}{{19}{2012}{{Hinton et~al.}}{{}}}
\bibcite{hinton2015distilling}{{20}{2015}{{Hinton et~al.}}{{}}}
\bibcite{huang2016deep}{{21}{2016}{{Huang et~al.}}{{}}}
\bibcite{jain1991unsupervised}{{22}{1991}{{Jain and Farrokhnia}}{{}}}
\bibcite{jolliffe2011principal}{{23}{2011}{{Jolliffe}}{{}}}
\bibcite{quickdrawgame}{{24}{2017}{{Jonas~Jongejan and Team}}{{}}}
\bibcite{karpathy2015deep}{{25}{2015}{{Karpathy and Fei-Fei}}{{}}}
\bibcite{kingma2014adam}{{26}{2014}{{Kingma and Ba}}{{}}}
\bibcite{howrnnworks}{{27}{2017}{{Kostadinov}}{{}}}
\bibcite{krizhevsky2012imagenet}{{28}{2012}{{Krizhevsky et~al.}}{{}}}
\bibcite{NIPS2010_4089}{{29}{2010}{{Larochelle and Hinton}}{{}}}
\bibcite{lecun2015deep}{{30}{2015}{{LeCun et~al.}}{{}}}
\bibcite{lecun-mnisthandwrittendigit-2010}{{31}{2010}{{LeCun and Cortes}}{{}}}
\bibcite{2014arXiv1405.0312L}{{32}{2014}{{{Lin} et~al.}}{{}}}
\bibcite{lowe1999object}{{33}{1999}{{Lowe et~al.}}{{}}}
\bibcite{marti1999full}{{34}{1999}{{Marti and Bunke}}{{}}}
\bibcite{mohammed2018handwriting}{{35}{2018}{{Mohammed et~al.}}{{}}}
\bibcite{Murphy:2012:MLP:2380985}{{36}{2012}{{Murphy}}{{}}}
\bibcite{Nam:2015:HDP:2786805.2786814}{{37}{2015}{{Nam and Kim}}{{}}}
\bibcite{narang2015speech}{{38}{2015}{{Narang and Gupta}}{{}}}
\bibcite{oord2016wavenet}{{39}{2016a}{{Oord et~al.}}{{}}}
\bibcite{oord2016pixel}{{40}{2016b}{{Oord et~al.}}{{}}}
\bibcite{s16010115}{{41}{2016}{{Ord\IeC {\'o}\IeC {\~n}ez and Roggen}}{{}}}
\bibcite{papineni2002bleu}{{42}{2002}{{Papineni et~al.}}{{}}}
\bibcite{pinheiro2014recurrent}{{43}{2014}{{Pinheiro and Collobert}}{{}}}
\bibcite{raina2009large}{{44}{2009}{{Raina et~al.}}{{}}}
\bibcite{robbins1951stochastic}{{45}{1951}{{Robbins and Monro}}{{}}}
\bibcite{rumelhart1988learning}{{46}{1988}{{Rumelhart et~al.}}{{}}}
\bibcite{seraphin2019analyzing}{{47}{2019}{{S{\'e}raphin-Thibon et~al.}}{{}}}
\bibcite{shi2010transfer}{{48}{2010}{{Shi et~al.}}{{}}}
\bibcite{shimodaira2000improving}{{49}{2000}{{Shimodaira}}{{}}}
\bibcite{silver2016mastering}{{50}{2016}{{Silver et~al.}}{{}}}
\bibcite{simonyan2014very}{{51}{2014}{{Simonyan and Zisserman}}{{}}}
\bibcite{sutskever2014sequence}{{52}{2014a}{{Sutskever et~al.}}{{}}}
\bibcite{Sutskever:2014:SSL:2969033.2969173}{{53}{2014b}{{Sutskever et~al.}}{{}}}
\bibcite{szegedy2015going}{{54}{2015}{{Szegedy et~al.}}{{}}}
\bibcite{taylor2008transferring}{{55}{2008}{{Taylor et~al.}}{{}}}
\bibcite{taylor2007cross}{{56}{2007}{{Taylor and Stone}}{{}}}
\bibcite{torrey2010transfer}{{57}{2010}{{Torrey and Shavlik}}{{}}}
\bibcite{maaten2008visualizing}{{58}{2008}{{van~der Maaten and Hinton}}{{}}}
\bibcite{791823}{{59}{1999}{{Viard-Gaudin et~al.}}{{}}}
\bibcite{DBLP:journals/corr/VinyalsTBE14}{{60}{2014}{{Vinyals et~al.}}{{}}}
\bibcite{vinyals2015show}{{61}{2015}{{Vinyals et~al.}}{{}}}
\bibcite{wagstaff2012machine}{{62}{2012}{{Wagstaff}}{{}}}
\bibcite{wang2016gating}{{63}{2016}{{Wang et~al.}}{{}}}
\bibcite{Wang2017AnAR}{{64}{2017a}{{Wang et~al.}}{{}}}
\bibcite{wang2017tacotron}{{65}{2017b}{{Wang et~al.}}{{}}}
\bibcite{weiss2016survey}{{66}{2016}{{Weiss et~al.}}{{}}}
\bibcite{convexfn}{{67}{2019a}{{Wikipedia}}{{}}}
\bibcite{gradientdescent}{{68}{2019b}{{Wikipedia}}{{}}}
\bibcite{xu2015show}{{69}{2015}{{Xu et~al.}}{{}}}
\bibcite{zen2014deep}{{70}{2014}{{Zen and Senior}}{{}}}
