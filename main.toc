\select@language {english}
\contentsline {part}{I\hspace {1em}Introduction and Problem Description}{17}{part.1}
\contentsline {xpart}{Introduction and Problem Description}{19}{part.1}
\contentsline {chapter}{\numberline {1}Introduction}{19}{chapter.1}
\contentsline {section}{\numberline {1.1}What is a style?}{19}{section.1.1}
\contentsline {section}{\numberline {1.2}Why studying styles?}{20}{section.1.2}
\contentsline {section}{\numberline {1.3}Why Handwriting?}{20}{section.1.3}
\contentsline {section}{\numberline {1.4}An overview of the PhD}{20}{section.1.4}
\contentsline {section}{\numberline {1.5}Disclaimer}{21}{section.1.5}
\contentsline {chapter}{\numberline {2}Datasets}{23}{chapter.2}
\contentsline {section}{\numberline {2.1}Introduction}{23}{section.2.1}
\contentsline {section}{\numberline {2.2}Online Handwriting -- \textit {IRONOFF}}{24}{section.2.2}
\contentsline {section}{\numberline {2.3}Sketch Drawing -- \textit {QuickDraw!}}{31}{section.2.3}
\contentsline {section}{\numberline {2.4}Data representation}{34}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Continuous or Discrete representation?}{42}{subsection.2.4.1}
\contentsline {paragraph}{Continuous Data Representation}{42}{section*.16}
\contentsline {paragraph}{Discrete Data Representation}{44}{section*.19}
\contentsline {subsection}{\numberline {2.4.2}Feature engineering: Direction and Speed}{44}{subsection.2.4.2}
\contentsline {section}{\numberline {2.5}Summary}{45}{section.2.5}
\contentsline {part}{II\hspace {1em}Experiments}{49}{part.2}
\contentsline {xpart}{Experiments}{51}{part.2}
\contentsline {chapter}{\numberline {3}Generation, benchmarks and evaluation}{51}{chapter.3}
\contentsline {section}{\numberline {3.1}Background}{53}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Deep Learning: quick overview}{53}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}A word about sequential data}{54}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}Recurrent Neural Networks and Sequence Generation}{55}{subsection.3.1.3}
\contentsline {subsection}{\numberline {3.1.4}Optimization Algorithms}{57}{subsection.3.1.4}
\contentsline {subsubsection}{Mini-batch optimization}{60}{section*.25}
\contentsline {subsection}{\numberline {3.1.5}Architectures}{60}{subsection.3.1.5}
\contentsline {subsection}{\numberline {3.1.6}Inference: How to generate sequences from the network?}{61}{subsection.3.1.6}
\contentsline {subsection}{\numberline {3.1.7}How to introduce prior to the model? (conditioning the model)}{63}{subsection.3.1.7}
\contentsline {paragraph}{Initialize the first hidden state directly}{65}{section*.28}
\contentsline {paragraph}{Using the first time-step}{65}{section*.29}
\contentsline {paragraph}{Using context sequence -- multiple time-steps --}{65}{section*.30}
\contentsline {paragraph}{Concatenating input time-steps with the condition}{65}{section*.31}
\contentsline {paragraph}{Concatenating the hidden state with the condition}{66}{section*.32}
\contentsline {subsection}{\numberline {3.1.8}How to evaluate the quality of generation?}{66}{subsection.3.1.8}
\contentsline {section}{\numberline {3.2}Putting all of that together}{66}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Our proposed evaluation metrics}{68}{subsection.3.2.1}
\contentsline {paragraph}{BLEU score}{68}{section*.34}
\contentsline {paragraph}{End of Sequence}{70}{section*.36}
\contentsline {subsection}{\numberline {3.2.2}How to ground the metrics?}{70}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Model used}{71}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Results}{73}{subsection.3.2.4}
\contentsline {subsubsection}{BLEU score}{73}{section*.39}
\contentsline {subsubsection}{Sequence length}{74}{section*.42}
\contentsline {subsection}{\numberline {3.2.5}Examples of the generated letters}{74}{subsection.3.2.5}
\contentsline {section}{\numberline {3.3}Summary}{76}{section.3.3}
\contentsline {chapter}{\numberline {4}Framework}{79}{chapter.4}
\contentsline {section}{\numberline {4.1}Background}{80}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Auto-encoders}{80}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Objectives}{80}{subsection.4.1.2}
\contentsline {subsection}{\numberline {4.1.3}Static and Temporal auto-encoder}{80}{subsection.4.1.3}
\contentsline {section}{\numberline {4.2}Putting it all together}{81}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Letter generation with style preservation}{81}{subsection.4.2.1}
\contentsline {subsection}{\numberline {4.2.2}Style transfer}{82}{subsection.4.2.2}
\contentsline {subsection}{\numberline {4.2.3}Styles per letters}{83}{subsection.4.2.3}
\contentsline {chapter}{\numberline {5}Style Extraction and Transfer}{95}{chapter.5}
\contentsline {section}{\numberline {5.1}Introduction and objectives}{96}{section.5.1}
\contentsline {section}{\numberline {5.2}Transfer learning}{97}{section.5.2}
\contentsline {paragraph}{Symmetric and Asymmetric transfer}{98}{section*.63}
\contentsline {subsection}{\numberline {5.2.1}Metrics to evaluate transfer learning}{98}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Homogeneous transfer learning}{100}{subsection.5.2.2}
\contentsline {subsubsection}{Symmetric - transfer learning using deep learning}{100}{section*.66}
\contentsline {subsubsection}{Parameter-based transfer}{102}{section*.68}
\contentsline {subsubsection}{Instance-based transfer}{102}{section*.69}
\contentsline {subsection}{\numberline {5.2.3}Heterogeneous transfer learning}{103}{subsection.5.2.3}
\contentsline {subsubsection}{Symmetric}{103}{section*.70}
\contentsline {subsubsection}{Asymmetric}{104}{section*.71}
\contentsline {subsection}{\numberline {5.2.4}Negative transfer}{104}{subsection.5.2.4}
\contentsline {section}{\numberline {5.3}Application of transfer learning}{105}{section.5.3}
\contentsline {subsection}{\numberline {5.3.1}Transfer between writers}{105}{subsection.5.3.1}
\contentsline {subsection}{\numberline {5.3.2}Transfer between tasks}{105}{subsection.5.3.2}
\contentsline {subsubsection}{IRONOFF}{105}{section*.72}
\contentsline {subsubsection}{QuickDraw!}{105}{section*.73}
\contentsline {section}{\numberline {5.4}Style Extraction}{105}{section.5.4}
\contentsline {section}{\numberline {5.5}Summary}{105}{section.5.5}
\contentsline {part}{III\hspace {1em}Discussion and Closing Remarks}{109}{part.3}
\contentsline {xpart}{Discussion and Closing Remarks}{111}{part.3}
\contentsline {chapter}{\numberline {6}Discussion}{111}{chapter.6}
\contentsline {section}{\numberline {6.1}Challenges}{111}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}Choice of the topic}{111}{subsection.6.1.1}
\contentsline {subsection}{\numberline {6.1.2}Determine the scope of interest in the state-of-the art}{111}{subsection.6.1.2}
\contentsline {subsection}{\numberline {6.1.3}Lack of Benchmarks, evaluation metrics}{112}{subsection.6.1.3}
\contentsline {subsection}{\numberline {6.1.4}Deep learning: theory, hardware and software frameworks}{112}{subsection.6.1.4}
\contentsline {section}{\numberline {6.2}Limitations of the current work}{112}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Style extraction and exploration using PCA and tSNE methods}{112}{subsection.6.2.1}
\contentsline {paragraph}{PCA}{113}{section*.77}
\contentsline {paragraph}{tSNE}{113}{section*.78}
\contentsline {subsection}{\numberline {6.2.2}Leak in the style module}{114}{subsection.6.2.2}
\contentsline {section}{\numberline {6.3}Future directions}{115}{section.6.3}
\contentsline {chapter}{\numberline {7}Closing Remarks}{119}{chapter.7}
\contentsline {chapter}{\numberline {A}List of publications}{121}{appendix.A}
\contentsline {section}{\numberline {A.1}International Conferences}{121}{section.A.1}
\contentsline {section}{\numberline {A.2}Posters and infomal communication}{121}{section.A.2}
