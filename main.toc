\select@language {english}
\contentsline {part}{I\hspace {1em}Introduction and Problem Description}{15}{part.1}
\contentsline {chapter}{\numberline {1}Introduction}{17}{chapter.1}
\contentsline {section}{\numberline {1.1}What is a style?}{17}{section.1.1}
\contentsline {section}{\numberline {1.2}Why studying styles?}{17}{section.1.2}
\contentsline {section}{\numberline {1.3}Why Handwriting?}{18}{section.1.3}
\contentsline {section}{\numberline {1.4}An overview of the PhD}{18}{section.1.4}
\contentsline {section}{\numberline {1.5}Disclaimer}{18}{section.1.5}
\contentsline {chapter}{\numberline {2}Datasets}{19}{chapter.2}
\contentsline {section}{\numberline {2.1}Introduction}{19}{section.2.1}
\contentsline {section}{\numberline {2.2}Online Handwriting -- \textit {IRONOFF}}{20}{section.2.2}
\contentsline {section}{\numberline {2.3}Sketch Drawing -- \textit {QuickDraw!}}{21}{section.2.3}
\contentsline {section}{\numberline {2.4}Data representation}{30}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Continuous or Discrete representation?}{37}{subsection.2.4.1}
\contentsline {paragraph}{Continuous Data Representation}{38}{section*.16}
\contentsline {paragraph}{Discrete Data Representation}{39}{section*.19}
\contentsline {subsection}{\numberline {2.4.2}Feature engineering: Direction and Speed}{40}{subsection.2.4.2}
\contentsline {section}{\numberline {2.5}Summary}{41}{section.2.5}
\contentsline {part}{II\hspace {1em}Experiments}{45}{part.2}
\contentsline {chapter}{\numberline {3}Generation, benchmarks and evaluation}{47}{chapter.3}
\contentsline {section}{\numberline {3.1}Background}{48}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Deep Learning: quick overview}{48}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}A word about sequential data}{49}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}Recurrent Neural Networks and Sequence Generation}{50}{subsection.3.1.3}
\contentsline {subsection}{\numberline {3.1.4}Optimization Algorithms}{52}{subsection.3.1.4}
\contentsline {subsubsection}{Mini-batch optimization}{55}{section*.25}
\contentsline {subsection}{\numberline {3.1.5}Architectures}{56}{subsection.3.1.5}
\contentsline {subsection}{\numberline {3.1.6}Inference: How to generate sequences from the network?}{56}{subsection.3.1.6}
\contentsline {subsection}{\numberline {3.1.7}How to introduce prior to the model? (conditioning the model)}{58}{subsection.3.1.7}
\contentsline {paragraph}{Initialize the first hidden state directly}{60}{section*.28}
\contentsline {paragraph}{Using the first time-step}{60}{section*.29}
\contentsline {paragraph}{Using context sequence -- multiple time-steps --}{60}{section*.30}
\contentsline {paragraph}{Concatenating input time-steps with the condition}{60}{section*.31}
\contentsline {paragraph}{Concatenating the hidden state with the condition}{61}{section*.32}
\contentsline {subsection}{\numberline {3.1.8}How to evaluate the quality of generation?}{61}{subsection.3.1.8}
\contentsline {section}{\numberline {3.2}Putting all of that together}{61}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Our proposed evaluation metrics}{63}{subsection.3.2.1}
\contentsline {paragraph}{BLEU score}{63}{section*.34}
\contentsline {paragraph}{End of Sequence}{65}{section*.36}
\contentsline {subsection}{\numberline {3.2.2}How to ground the metrics?}{65}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Model used}{66}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Results}{68}{subsection.3.2.4}
\contentsline {subsubsection}{BLEU score}{68}{section*.39}
\contentsline {subsubsection}{Sequence length}{69}{section*.42}
\contentsline {subsection}{\numberline {3.2.5}Examples of the generated letters}{69}{subsection.3.2.5}
\contentsline {section}{\numberline {3.3}Summary}{71}{section.3.3}
\contentsline {chapter}{\numberline {4}Framework}{75}{chapter.4}
\contentsline {section}{\numberline {4.1}Background}{76}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Auto-encoders}{76}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Objectives}{76}{subsection.4.1.2}
\contentsline {subsection}{\numberline {4.1.3}Static and Temporal auto-encoder}{76}{subsection.4.1.3}
\contentsline {section}{\numberline {4.2}Putting it all together}{76}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Letter generation with style preservation}{76}{subsection.4.2.1}
\contentsline {subsection}{\numberline {4.2.2}Style transfer}{78}{subsection.4.2.2}
\contentsline {subsection}{\numberline {4.2.3}Styles per letters}{78}{subsection.4.2.3}
\contentsline {chapter}{\numberline {5}Style Extraction and Transfer}{91}{chapter.5}
\contentsline {section}{\numberline {5.1}Introduction and objectives}{91}{section.5.1}
\contentsline {section}{\numberline {5.2}Transfer learning}{91}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Notation and problem definition}{92}{subsection.5.2.1}
\contentsline {paragraph}{Symmetric and Asymmetric transfer}{93}{section*.63}
\contentsline {subsection}{\numberline {5.2.2}Metrics to evaluate transfer learning}{93}{subsection.5.2.2}
\contentsline {subsection}{\numberline {5.2.3}Homogeneous transfer learning}{95}{subsection.5.2.3}
\contentsline {subsubsection}{Symmetric - transfer learning using deep learning}{95}{section*.66}
\contentsline {subsubsection}{Parameter-based transfer}{97}{section*.68}
\contentsline {subsubsection}{Instance-based transfer}{97}{section*.69}
\contentsline {subsection}{\numberline {5.2.4}Heterogeneous transfer learning}{98}{subsection.5.2.4}
\contentsline {subsubsection}{Symmetric}{98}{section*.70}
\contentsline {subsubsection}{Asymmetric}{98}{section*.71}
\contentsline {subsection}{\numberline {5.2.5}Negative transfer}{99}{subsection.5.2.5}
\contentsline {section}{\numberline {5.3}Application of transfer learning}{100}{section.5.3}
\contentsline {subsection}{\numberline {5.3.1}Transfer between writers}{100}{subsection.5.3.1}
\contentsline {subsection}{\numberline {5.3.2}Transfer between tasks}{100}{subsection.5.3.2}
\contentsline {section}{\numberline {5.4}Style Extraction}{100}{section.5.4}
\contentsline {section}{\numberline {5.5}Summary}{100}{section.5.5}
\contentsline {part}{III\hspace {1em}Discussion and Closing Remarks}{101}{part.3}
\contentsline {chapter}{\numberline {6}Discussion}{103}{chapter.6}
\contentsline {section}{\numberline {6.1}Challenges}{103}{section.6.1}
\contentsline {subsection}{\numberline {6.1.1}Choice of the topic}{103}{subsection.6.1.1}
\contentsline {subsection}{\numberline {6.1.2}Unclear state-of-the art}{103}{subsection.6.1.2}
\contentsline {subsection}{\numberline {6.1.3}Lack of Benchmarks, evaluation metrics}{104}{subsection.6.1.3}
\contentsline {subsection}{\numberline {6.1.4}Deep learning: theory, hardware and software frameworks}{104}{subsection.6.1.4}
\contentsline {section}{\numberline {6.2}Limitations of the current work}{104}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Style extraction and exploration using PCA and tSNE methods}{104}{subsection.6.2.1}
\contentsline {paragraph}{PCA}{105}{section*.73}
\contentsline {paragraph}{tSNE}{105}{section*.74}
\contentsline {subsection}{\numberline {6.2.2}Leak in the style module}{106}{subsection.6.2.2}
\contentsline {section}{\numberline {6.3}Future directions}{107}{section.6.3}
\contentsline {chapter}{\numberline {7}Closing Remarks}{111}{chapter.7}
