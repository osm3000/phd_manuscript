\chapter{Style Extraction and Transfer}
\minitoc% Creating an actual minitoc

\par We finally arrive to the core objective of the PhD: how to leverage information of style from one (or more) \Gls{task}/s, in order to bootstrap the learning of a new task?


\section{Introduction and objectives}
  % \begin{itemize}
  %     \item Explain different paradigms and metrics used to characterise transfer learning.
  %     \item Why extracting style?: on our side, as ML practitioners, the ultimate objective of using ML is to help us extract new knowledge
  %     \item The questions of research here: extracting styles from bottleneck, transfer between writers, transfer between tasks
  % \end{itemize}

  \par Before we dive into the technical details, it is important to motivate why do we need to perform this in the first place. A common scenario is that we collect data over time for a particular task. This process can be quite expensive (e.g., collecting data from the robots is a slow and expensive process). Then, a new task of interest emerges. This task has common aspects with the old one. The question here is if we can leverage this common aspects, in order to boostrap the learn the new task.

  % For example, in case of handwriting, when trying to write new letters, and need to have the skill of using the pen, and performing micro-actions, like curves and straight lines. In the case of new letters, we need to recombine those mico-actions with new actions, in order to draw the new letters. Another example, in case of humans, is grasping objects. If you learn how to hold a plastic bottle, then you try to hold a glass cup, there are a lot of atomic actions in common, but the forces you apply are different.

  \par Examples of transfer learning:
  \begin{itemize}
      \item If you know how to hold a glass cup, with little adjustments, you can learn how to hold a plastic bottle.
      \item If you know probability and algebra, you can use this knowledge in order to boostrap/accelerate your progress in mastering machine learning.
  \end{itemize}

  \par There are plenty of cases where transfer learning is/could be useful, like:
  \begin{itemize}
    \item In robotics \citep{konidaris2012robot,Konidaris:2012:TRL:2188385.2343689}, collecting data can be quite expensive process, due to hardware limitations from one side, and human limitatio as well (in case of human-robot interaction scenarios). In addition, with techniques like reinforcement learning \citep{sutton2018reinforcement}, where the agent learns by trial and error, the process can be prohibitively slow, with safety concerns sometimes.
    \item In underwater acoustics \citep{malfante2018automatic}, an essential task is collecting and cleaning the data about the different fish sounds. This is a tediously manual job, and any change (type of fish, time of the day or place in the ocean) degrades the quality of prediction a lot. Transfer learning can be very useful in this case, to reduce the effort needed to collect, clean and annotate the data.
  \end{itemize}

  \begin{mdframed}[backgroundcolor=blue!20]
      \begin{center}
          Points addressed in this chapter
      \end{center}

      \begin{itemize}
          \item What is transfer learning? and what are the different approaches to perform it? I will explain the different paradigms and metrics used to characterise transfer learning.
          \item How do we approach the problem of style transfer, for both handwriting and sketch drawing?
          \item The experiments performed, the results, and our conclusions.
      \end{itemize}
  \end{mdframed}

\section{Transfer learning}\label{sec:transfer_learning}
  \par An important research direction in machine learning nowadays is transfer learning. If humans and machines are able to learn how to perform a task, one of the thing that separates humans from machines is the ability to leverage this knowledge in order to acquire new skills and perform new tasks, without the need for additional trials and errors from tabula rasa. This however, is not a straightforward thing for machine learning to do. The algorithms are fitted to data responding directly to the task required (i.e., has the same input feature space and same distribution). Thus, a change in the task can lead to degradation in the algorithm performance \citep{shimodaira2000improving,pan2009survey,weiss2016survey,dtl2018survey}.

  % \par In the following subsections, I first introduced notations and clear description for the objective of transfer learning, and the metrics used to evaluate the quality of transfer. I then discuss different types of transfer learning, with examples on each type.

  % \subsection{Notation and problem definition}
  \par Let's first introduce some notations that will help in formulating the problem:
  \begin{itemize}
      \item We first introduce the concept of \textit{Domain}. A domain defines a feature space (e.g., images of animals), and the probability distribution of this space (i.e., the distribution of pixels in the images of animals). We can consider the domain as the available \textit{knowledge} to us. Thus, a domain $\mathcal{D}$ is defined as $\mathcal{D} = \{\mathcal{X}, P(X)\}$, where:\\
      $\mathcal{X}$ is the feature space, $X$ is the data samples available to us from the feature samples, $X = \{x_1,x_2,\cdots,x_n\} \in \mathcal{X}$, where $n$ is the size of the learning sample. $P(X)$ is the marginal distribution probability of this data sample.

      \item For a given domain (aka, the knowledge available to us), we define a the concept of a \textit{task}. A task is something we would like to achieve using the knowledge we have. For example, a task can be classifying animals given animal pictures, or perform robot navigation given a map of the building. Thus, a task $\mathcal{T}$ is defined as $\mathcal{T} = \{\mathcal{Y}, f(.)\}$, where:\\
      $\mathcal{Y}$ is the label space (the task objectives), $f(.)$ is the mapping function (mapping the domain knowledge to the task objectives). It can also be rewritten as a conditional probability over the domain knowledge, $\mathcal{T} = \{\mathcal{Y}, P(Y|X)\}$.

      \item Based on this notation, we define two more concepts: \textit{Source} and \textit{Target}. A source defines a domain and a task/s that are available to us already (where we have plenty of domain knowledge, and examples on the task/s). A target defines a domain and a task/s as well, where we usually do not have enough domain knowledge and/or examples on the task/s.
  \end{itemize}

  \par Now that we clarified some basic terminology, we can move on to define transfer learning: given source domain data $D_S$, source task $\mathcal{T}_S$,  target domain $D_T$ and target task $\mathcal{T}_T$, we wish to improve the performance of the target task $f_T(.)$ by using $D_S$ and $\mathcal{T}_S$.

  \par Given this definition, we can categorize different types of problems that transfer learning covers:

  \begin{itemize}
      \item The source and taget domains are different, $D_S \neq D_T$, which means that the feature space is different, $\mathcal{X}_S \neq \mathcal{X}_T$, and/or the probability distribution of the feature space are not the same, $P(X_S) \neq P(X_T)$. If $\mathcal{X}_S \neq \mathcal{X}_T$, the transfer learning problem is \textit{Heterogeneous}. Otherwise, it is \textit{Homogeneous}.

      \item The source and target tasks are different, $\mathcal{T}_S \neq \mathcal{T}_T$, which means that the objectives are different, $\mathcal{Y_S} \neq \mathcal{Y_T}$, and/or the mapping function (from the feature space to the objectives) are different, $P(Y_S|X_S) \neq P(Y_T|X_T)$.
  \end{itemize}

  \par Many approaches in order to achieve transfer learning has been proposed in the literature. We will discuss the different approaches, and give examples from the literature on each one. We follow the categorization of transfer learning approaches done in \citep{dtl2018survey}\endnote{Other categorization exists, like the one used in \citep{weiss2016survey}. When it comes to deep transfer learning, we believe the one in \citep{dtl2018survey} to be the most relevant.}, by first identifying two main categories of transfer learning:
  \begin{itemize}
    \item \textit{Instances-based}: in this case, we utilize examples from the source domain into the training of the new target domain, by defining weights on them.
    \item \textit{Mapping-based}: the objective in this case is to project the instances from the two domains into a new manifold, that increases the similarity between the two domains.
    \item \textit{Network-based}: the more common type of deep transfer learning. It is based on the idea that the layers of the deep neural network extracts basic and general information, that shared a lot with other domains. In this case, the network or some of its layers are re-used on the target task.
    \item \textit{Adversarial-based}: similar objective to \textit{Mapping-based}, by using generative adversarial networks \citep{goodfellow2014generative} in order to find a manifold that are fit for both source and the target domains.
  \end{itemize}

  \par In the context of \textit{deep transfer leaning} -- the main domain in our work --, we find the \textit{Network-based} and \textit{Adversarial-based} transfer are the relevant categories in this case. \textit{Adversarial-based} transfer is quite recent, and there is not much to talk about at the moment, so we will focus \textit{Network-based} transfer, as it is the most common type of deep transfer learning.

  \par When it comes to evaluating the success of the transfer, there is no one way to evaluate transfer learning in general. This depends a lot on the objectives of transfer learning, and the criteria of success. In the case of machine learning, the improve in end quality of the model is the primary performance aspect being measured and reported -- like the classification accuracy \citep{chattopadhyay2012multisource,long2013transfer,pan2010cross,glorot2011domain}, the reduction in the average error \citep{pan2010domain}, ...etc --. The transfer is considered successful if it achieves better performance to the baseline method.

  \par We expect that, with the introduction of transfer learning via deep learning, that the \textit{time to train} the model could be another aspect to consider -- similar to what is being used in reinforcement learning \citep{taylor2007cross} --, although -- to the best of our knowledge -- we do not find studies mentioning this at the moment.

  \subsection{Network-based transfer learning}
    \par The idea of using deep learning~\citep{lecun2015deep} in order to achieve transfer learning has gain popularity during the last years, following the achievements in having better computational resources~\citep{raina2009large}, and the availability of large benchmark datasets - most notably: ImageNet~\citep{imagenet_cvpr09} for object detection, MS-COCO~\citep{2014arXiv1405.0312L} for image captioning~\ldots.

    \par The first notable success of deep learning happened in the area of computer vision, with the AlexNet architecture~\citep{krizhevsky2012imagenet}. It was found out that such a deep network manages to extract generic features about the images: it learns simple, hierarchical filters, that are generic enough to be applicable for different datasets (see figure~\ref{fig:AlexNet_filters}). This observation led to another surge in the usage of pretrained AlexNet -- and later newer architectures, like VGG16~\citep{simonyan2014very}, Inception~\citep{szegedy2015going},...etc -- as feature extractors for new, unseen datasets.

    \begin{figure}[!htbp]
      \centering
      \includegraphics[scale=0.4]{images/sota/filt1.jpeg}
      % \caption{Visualization of the first convolution layer of a trained AlexNet. The weights are very nice and smooth, indicating nicely converged network. Note also the basic simple shape of filters. It easy to imagine that those same filters will be useful in other computer vision or image related tasks.}
      \caption[Convolution Neural Networks filters shape]{Visualization of the first convolution layer of a trained AlexNet. Note the basic shape of filters that resemble to Gabor filters widely used in image processing for decades \citep{fogel1989gabor,jain1991unsupervised}. It is possible to see that those same filters will be useful in other computer vision or image-related tasks.}
      \label{fig:AlexNet_filters}
    \end{figure}

    \par It is interesting to note that those filters can be also seen as a representation for the skills we want to extract. In our case, we will need to combine both deep convolution network with a recurrent neural network (like in \citep{s16010115,pinheiro2014recurrent,huang2016deep}).


    \paragraph{Sentiment Classification}
     \citep{glorot2011domain} discusses a deep learning approach for transfer learning for sentiment classification, by using stacked de-noising auto-encoders \citep{vincent2008extracting} to correct the marginal distribution between the source and the target domain, by learning latent variables/features common between the two data sources in two steps:
    \begin{itemize}
        \item First, train an auto-encoder on the unlabeled data from the source and the target. This will produce latent variables that will make $P(X_S)$ closer to $P(X_T)$.
        \item Use those latent features to train a classifier on the labeled source data.
    \end{itemize}
    \par Experiments are done on 12 different sources and target domain pairs. The data used reviews for different products (4 different products). The performance metric used in this case is the classification error rate when using a classifier trained on the source task only, minus the classification error rate of a classifier trained on the target task only. A SVM classifier trained on the source domain is used as a baseline, and a comparison with other transfer methods \citep{blitzer2006domain,li2008multi,pan2010cross}. All these methods performs better than the baseline, and \citep{glorot2011domain} peforms better than all of them.

    \paragraph{Underwater Acoustics}
     \citep{malfante2018use} compares the use of deep transfer learning to manual features \citep{malfante2016automatic,malfante2018machine}, in order to recognize the sounds of fish underwater. Interestingly, the deep learning models are trained on ImageNet \citep{imagenet_cvpr09} dataset (which is completely unrelated to acoustics), then used in order to extract features from the spectrogram of the underwater recordings. The assumption here is the the filters learned with deep learning are basic and generic enough, to be used in other domains, thus, deep learning can provide a natural correction for $P(X_S)$, to make it close to $P(X_T)$. Without any finetuning, the deep learning achieves quite a high perfomance, although less than the state of the art, suggesting that a further investment in this direction is worth the time.

    \paragraph{Speech modeling}
    \citep{xu2014cross} studies the idea of transfering the speech knowledge learned from one language pair to another using deep neural networks. In particular, the study the transfer between Mandarin and English (in both ways). Their hypothesis is that when modeling the speech in a language, there is a part in the model that is language independent. Their work was to find this part, and use it to bootstrap the learning of a new language (in case of neural networks, this can be rephrased as trying to find the good part in the neural network that is language independent).

    The compare to a deep learning model trained on the target task only, and compare the different the usage of different layers of a deep neural network trained on the source task (in order to determine the best part, or the language independent part). They report multiple performance metrics: segmental SNR (SSNR), log-spectral distortion (LSD), and perceptual evaluation of speech quality (PESQ). They find that, given insufficient data on the target task (which is one of the motivations to perform transfer learning), this transfer scheme works better than the baseline.

    \paragraph{Image classification}
    \citep{oquab2014learning} investigated the usage of a convolution neural network (CNN) trained on ImageNet \citep{imagenet_cvpr09} (where the object of interest is centered in the image), to extract low-level and mid-level features, that can transfer well to more complex dataset, PASCAL VOC \citep{everingham2010pascal} (where there are several objects of interest in the image), and is smaller than ImageNet. They use the \textit{average percision} as their peformance metric, and they show that the transfer is better than training a model from scratch on this target dataset.

  % \subsection{Adversarial-based transfer learning}
  % \par Encouraged by the recent advances in generative adversarial networks (GANs) \citep{goodfellow2014generative}, a new line work is trying to utilise this tool to achieve transfer learning, on the assumption that a good representation (suitable for transfer) should be general enough that it does not discriminate between the source and the target domains, yet discriminative enough to learn the required tasks on either domains.
  %
  % \subsection{Negative transfer}
  % \par A concern that arises in transfer learning is what is called \textit{negative transfer}, where the knowledge learned from one task leads to no improvement on the target task, or reduction in the quality of learning for that task. This can happen for multiple reasons \citep{rosenstein2005transfer}:
  % \begin{itemize}
  %     \item The source task is not sufficiently related to the target task, thus, in the best case scenario, no useful knowledge can be transferred.
  %     \item The transfer method is not able to exploit the similarities between the source and the target task
  % \end{itemize}
  % In \citep{rosenstein2005transfer}, the authors studied this problem, and provided examples for negative transfer.
  % Within the framework of \textit{reinforcement learning}, some methods can estimate task similarity \citep{taylor2008transferring, torrey2010transfer}, though these methods do not provide any theoretical guarantees about their effectiveness. This, however, is an open area of investigation in the framework of \textit{supervised learning} \textbf{CAN'T FIND RESOURCES HERE}. The main thing here for us to be careful during the choice/design of the source and the target experiments, to ensure that a possible positive transfer learning can happen.

\section{Application of transfer learning}
  \par In the previous section, we explored the concept of transfer learning, and the different categories mentioned in the literature about this
  In the section, I will explain the work done during the PhD on transfer learning. There are two questions we addressed:
  \begin{itemize}
      \item Transfer between writers
      \item Transfer between tasks
  \end{itemize}

  \subsection{Transfer between writers}
  \subsection{Transfer between tasks}

    \subsubsection{IRONOFF}
    \subsubsection{QuickDraw!}
      \begin{figure}
        \centering
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_circle_target_strokes_heatmap.png}
        \end{subfigure}
        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_circle_transfer_strokes_heatmap.png}
        \end{subfigure}

        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_triangle_target_strokes_heatmap.png}
        \end{subfigure}
        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_triangle_transfer_strokes_heatmap.png}
        \end{subfigure}

        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_square_target_strokes_heatmap.png}
        \end{subfigure}
        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_square_transfer_strokes_heatmap.png}
        \end{subfigure}

      \end{figure}
      \begin{figure}\ContinuedFloat

        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_hexagon_target_strokes_heatmap.png}
        \end{subfigure}
        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_hexagon_transfer_strokes_heatmap.png}
        \end{subfigure}

        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_octagon_target_strokes_heatmap.png}
        \end{subfigure}
        ~
        \begin{subfigure}[tb]{0.45\textwidth}
            \includegraphics[width=\textwidth]{images/sota/quickdraw_results/quickdraw_octagon_transfer_strokes_heatmap.png}
        \end{subfigure}

        \caption{QuickDraw! Confusion matrix for strokes for both baseline and transfer modes, on the different tasks.}
        \label{fig:quickdraw_strokes_cnf}
      \end{figure}


\section{Style Extraction}

\section{Summary}
