\chapter{Closing Remarks} \label{ch:closing_remarks}
\minitoc% Creating an actual minitoc

\par Here we arrive to the end of the journey. I would like to take the space here to summarize what were the objective of my thesis and the motivation behind those objectives, what was achieved during this thesis.

% \begin{itemize}
%     \item Summarize the vision and the objectives of the PhD
%     \item
% \end{itemize}
\section{At the beginning...}

  \par We started with a hypothesis that, any task human do consists of two parts: a content/identity (the core of the task) and the style (the manner the task is performed). My thesis represents our interest in studying styles, in the framework of machine learning. The reason for using machine learning is that data are becoming more complex, and applying traditional tools on it directly is no longer effective. Machine learning provide a tool for scientific research in order to explore large amounts of data; as an inquiry to see if particular information exists (as in classification), or in summarizing and compressing the data into suitable manifold, that we can perform analysis on.

  \par Dealing with styles is a problem that emerges in many areas, most relevant to us, in case of human-robot interaction. Applying machine learning algorithms in a naive way directly on the data in order to learn models of human behavior leads to an averaging phenomena, where the specific style of the humans are averaged and removed. Thus, we need to find a way to extract those styles, and enable the machine learning algorithm to take into account while building models of interaction. Taking the style of each human partner into account during the interaction is important in order for the human to have a better experience, thus allowing some level of trust and confidence to emerge during the interaction.

  \par The problem of styles is ill-defined, and poses a lot of challenges in the way we can approach it. It is not clear how to think about the problem, what framework to use, what suitable metrics to evaluate the styles, and to what benchmarks we should compare different methods. Some think about styles in an explicit way -- some particular aspects exist -- and some think about it in an implicit way -- generating behaviors and comparing them to the desired behaviors --. Besides, we do not have suitable data in the area of human-robot interaction in order to performs such study. Building this data set from scratch would have been very expensive.

  \par In order to have a more controlled environment, where we can study styles, we focused our attention on another problem, that we believe has relevant characteristics to our original objective: online handwriting and sketch drawing. There are several advantages of working on such domain, like the availability of large quantities of annotated data, and the task content/identity is well defined. This allowed us to focus on the problem of developing proper methods to study styles.

  \par We were curious about the idea of styles in different tasks: how can we study them? is it possible to extract them? and if so, are they transferable between different tasks? Transferability of styles between task is an immensely useful idea; it can save us a lot of work in terms of collecting and annotating new data. Plus, it can allow us to better understand the common styles and aspects between different tasks.

\section{What did we do?}

  \par The first step is to break these general objectives into smaller ones, address these small objectives, and then combine them to realize the original general objectives. For the case of studying styles, we did not have any evaluation metrics, benchmark to compare to, framework to reason about styles. All these points are entangled together; tackling one of them will affects the others.

  \par We first decided to use an implicit way to look at styles, by generating behaviors and evaluating them. Thus, given the plenty of data available, we went for deep generative models framework. We proposed evaluation metrics, but they need to be grounded -- even if they look logical --, so we proposed multiple benchmarks, that we know beforehand their relative power, and used this knowledge in order to ground the proposed metrics. See chapter~\ref{ch:GBEM} for more details.

  \par Once the basis were laid, it was time to study styles. We used a conditioned-autoencoder to study styles. The condition was on the task identity/content, thus letting the autoencoder focus on learning relevant style information. We analyzed the latent space, and showed some examples of the extracted styles -- some of them we were not aware of their existence before --. See chapter~\ref{ch:framework} for more details.

  \par Once we successfully extracted styles, we had a strong interest in transferring those styles between different tasks. This is especially important when collecting and annotating data is expensive (like in case of human-robot interaction). We capitalized on the success of the conditioned-autoencoder framework we used, by reusing the relevant part (the encoder/style extractor) in one new task. We expanded and refined the the evaluation metrics we use, and we added another data set, and performed extensive statistical tests to investigate our methods. We showed the validity and the potential of our approach. See chapter~\ref{ch:seat} for more details.

  \par Finally, I presented what I believe as the take-away message from my personal experience during this PhD. I discussed the challenges faced (from choosing the choice of the research point. diversity of the literature, the lack of benchmark and performance metrics and the proper usage of deep learning), and the shortcomings of my work (the need for better/more specialized methods to explore the latent space and extract styles, and the leak of information about the task identity/content in the style extraction module), and what I think is the potential directions to investigate (the proper structuring of the latent space, the data efficiency aspect, and better realization and understanding for the physical implication of the evaluation metrics we used). See chapter~\ref{ch:discussion} for more details.

% \section{section name}
