\chapter{Discussion} \label{ch:discussion}
% \minitoc% Creating an actual minitoc

This chapter will be a free discussion about what i had done, shortcomings of this work, difficulties in the PhD, and potential areas of development.

Science should always be about honesty, humility and respect, and not just flashy results and wide conclusions. Science can always make use of learning from setbacks -- something that is almost missing in the scientific literature --. I will do my best in this chapter to highlight the other side of good results.

Maybe one day someone -- maybe a PhD student -- will decide to follow on this work. It is important for me that they do not repeat the same mistakes. Instead, everything should be ready for them in order to make new mistakes. That is how we move forward...

\clearpage

\section{Challenges}

\subsection{Choice of how to tackle the topic?}
\par The usage of deep learning in this topic has not been the first or clear option from the beginning. As I mentioned earlier, the objective of the project was to develop components for human-robot interaction domain. In a first glance, deep learning and human-robot interaction do not really mix well. The problem is simply the availability of data.

\par There is a stretch of imagination in this thesis, that we assume -- and I believe rightly so -- that the data problem in HRI will be resolved in the future. Better and more reliable hardware is becoming available, and there is a general awareness now in the community about the need to do something concerning the data: a lot of data is being recorded by the research group, but there is no standardization or culture of open sourcing the data, even within the same team, leading to a big waste of efforts and time.

\par At first, it seems that more data-efficient methods -- that depends on well designed priors from humans -- are the way to go in such project. However, the advances in deep learning application in areas like speech synthesis, image captioning, text and music generation, and the lucrative possibilities that data-driven approaches provide were hard to ignore. Besides, the current advances in machine learning indicate that computational approaches, even with simple algorithms, are outperforming methods that depends on human knowledge and prior\footnote{As nicely noted by Richard Sutton, one of the god fathers of reinforcement learning, in his article \textit{The bitter lesson}, \url{http://incompleteideas.net/IncIdeas/BitterLesson.html}}.

\subsection{Determine the scope of interest in the state-of-the art}

\par A major challenge during the PhD was to determine the relevant state of the art. For generative models, the usage of deep learning methods was not the clear choice of the beginning, and once chosen, it took considerable effort to determine the scope of the relevant literature.

\par The same goes for the state of the art on styles. The word itself, and the range of study, is very wide -- as noted early in the introduction. By far, the work done in handwriting styles was the least relevant to our work; either because the work is done on offline handwriting (thus not dealing with the dynamics of writing itself) -- and this is most of the work done currently --\endnote{Most of the great advances that happened recently in neural networks -- especially in generative models -- is related to computer vision. Thus, it is more convenient to deal with with handwriting as images than as a dynamic process.}. The problem does not always manifest itself in a technical shape, sometimes -- and most annoying -- it is mostly that we do not know what we are looking for exactly, and even if we do know, we do not know the exact terminology other people are using to describe it.

% \par The only way to tackle this issue was a brute force attack on the state of the art: read each and everything, decide the potential directions to focus on, build prototypes for these potential solutions, getting disappointed, tinker with the prototypes, and

\par I am thankful for the great deal of openness that researchers in machine learning are embarrassing. The discussions through online forums, blogs, tutorials, online courses, and recent books, had definitely made this massive task more tractable.

\subsection{Lack of Benchmarks, evaluation metrics}
Getting around these issues was quite a dilemma, for many reasons:

\begin{itemize}
    \item I do not believe it is a healthy practice to pick up the benchmarks to use. This choice can be easily biased, and it could be argued that the benchmarks are chosen to be weak enough in order to show progress). In our case, it was mandatory to do so nonetheless, and we tried as much as possible to be fair in making these choices.
    \item In engineering, it is a good practice to have different teams for design and verification of the product. If one team do both, the validation process tend to be biased (i.e., the team is looking for confirmation of their design, not the problems in it). By analogy, I think this a pitfall of us developing the metrics and using them. What if we are mainly looking at the metrics that confirms our hypothesis? It is hard to rule out this possibility.
\end{itemize}

We tried our best to avoid this when selecting the metrics, and by using multiple metrics to evaluate our hypothesis.

\subsection{Deep learning: theory, hardware and software frameworks}
\par

\section{Limitations of the current work}
In this section, I discuss what I consider shortcomings for some of the methods used in this work.

\subsection{Style extraction and exploration using PCA and tSNE methods}
In this work, when exploring the latent space of our model, I used either PCA or tSNE projection methods (to project the latent space from the high dimensional space into a smaller one), and tried to use the assumptions behind both methods to extract meaningful information from the latent space.

While this is legit, it really stretches these methods to the breaking point, plus, it hinders further investigation.

\paragraph{PCA} assumes orthogonality and linearity in the space being projected. There is no reason however to assume that these assumptions hold for different styles.
In the non-linearity aspect, the latent space does not have the clear objective of transferring non-linear style relationship into linear ones (simply, because no such objective can be formulated directly, since the problem of styles is ill-defined), unlike what can be noticed for the last layers of classifiers (where an embedded objective of the network is project the data from their non-linear manifold into a linear one).
Founding orthogonality in the style space is an interesting aspect to explore, but this is a strong assumption, and there is no reason to believe that it holds for all aspects of styles.
.
\paragraph{tSNE} provide us with a way to deal with non-linearity, thus allowing another further exploring the latent space, but it is hard to repeat the results (the method is stochastic) and the projection does not always yield clear information about the styles. Changing the \textit{perplexity} parameter leads to different results as well (I didn't explore the relation of that parameter to find a more suitable style manifold, and I am not sure if it is worth the effort).

But what is a good projection criteria in this case? should we let the organization of styles emerge on its own, by constraining the latent space and add regularization to the loss function (i.e., during an end-to-end training of the network)? should a second optimization step be performed on the latent space, in order to disentangle it? I discuss some of these ideas briefly in section \ref{sec:future_direction}.

\subsection{Leak in the style module}
\par In a basic autoencoder (no condition on the bottleneck), one can assume that encoder part will learn the identity of the task + the style in the same time. The idea of conditioning is to provide the task description (aka: task identity) as an input to the decoder (the condition), thus, relieving the encoder from learning it, and focus only on learning the styles, thus enhancing the style transfer capability.

Ideally, we expect that the output of the encoder has little to none information about the task identity. However, careful testing shows that this is not the case. There is a considerable leak of information about the task identity into the encoder.

\textbf{PUT THE RESULTS OF OUR TESTING HERE. TRY IF POSSIBLE TO COMPARE WITH A NORMAL AUTOENCODER.}

I don't have an explanation at the moment for the reason behind this phenomena. My intuition\endnote{I did not have the time to perform rigorous testing for this idea unfortunately.} is that on aspect of the problem lies in the task description. The assumption that a harsh one-hot encoding of the task is sufficient to describe the task correctly is flawed in my opinion.

An analogy for this can been drawn from clustering (hard clustering VS fuzzy clustering). Hard clustering, similar to one-hot encoding, does provide us with which this task is, but nothing about how this task relates to other tasks (i.e., proximity/similarity to other task), which is what fuzzy clustering do.

The influential work done by Geoffrey Hinton in \cite{hinton2015distilling} -- performed on the MNIST dataset \cite{lecun-mnisthandwrittendigit-2010} -- is a contributing factor in this intuition. I will not dive into details about this article here, since it is outside the scope of this work, I will just mention two interesting results from this study:

\begin{itemize}
    \item In a classification task, the traditional description of the labels is one-hot encoding. However, using a soft/fuzzy description of the labels reveals much better results (makes sense, since it is more rich in information).
    \item If you train a classifier on the soft labels of digits 7 and 8 only, the classifier will perform almost 90\% accuracy on the other labels \endnote{I personally find this particular result fascinating.}!. It means that a better task description may increase the data efficiency of the model.
\end{itemize}
A similar concept should definitely be explored in the context of this work.

\section{Future directions}\label{sec:future_direction}
\textbf{Separate the technical parts (very tactical/low-level) from the research parts (strategic/high-level/long-range)}

\begin{itemize}
    \item Embedding (robust generalization/maybe style extraction)
    \item Multi-stage optimization (for style extraction) (research)
    \item Disentanglement of styles / latent space distributions / loss OR constraint (for knowledge extraction): interesting for extracting new styles AND building behavior generators. (research)
    \item RL and planning to reduce the complexity/have control over the generation and evaluation process (not sure)
    \item Memories of the neural network for better task decomposition (useful for transfer learning) -- maybe report my experiment with the external memory here. (research)
    \item Statistical testing for neural network performance and for the inference quality + the effect of the random seed. (engineering/deployment)
    \item Better task description (research)
    \item Automatic separation of task and style (research)
    \item Data efficiency and Model Complexity (engineering/deployment)
    \item Define data augmentation protocol: while many techniques exists for images, it is not so clear in case of sequences. (research)
    \item \textbf{Treating dynamical system as an image, with coloring gradients representing the dynamics of the system}: this will give us massive power in using the SOTA of generative models developed for static images (based on GANs), while addressing all the characteristics of the dynamical system in the same time.

    This is similar to treating sound waves as images (the ML course I did with Washington University), or spectrum images (like what i did with Marielle).

    \item Dealing with style extraction as an embedding problem: \textbf{NOTE: i am not sure if we didn't do that already. Probably in the shaping of the latent space or the loss function. Or maybe it is already okay now. }

    \item Modeling the error distribution of the model during the generation phase: in order to enhance the quality of the generation, and reduce the distance between the generation and the prediction (i.e., the training and the usage phases) \endnote{nothing, quick test}.

    \item World models paper: having a model of the world, and use it to train a proper generator using RL.

    \item Re-visiting MDN (even the in discrete case): a useful tool, even for finite-discrete distribution. Mixed with good embedding, and giving 'uncertainty' level, provides important information. This also has a very good potential for optimization.

    \item Using RL for generation instead of log-likelihood models, and free the metric and the study from the constraints of differentiability.
    \item The hyper-parameter tuning: Do we need it? And how to do it efficiently? (yes we do need it. the question is how to do it in an effecient manner).

    \item Evaluate the quality of the content/task generated, not just the style: usually done via subjective testing or using another model -- which i strictly refuse --. Subjective testing is too slow.

    \item What do these numbers actually mean in real life? how much should we care? \cite{wagstaff2012machine} (machine learning that matters paper): we used multiple metrics in order to compare/assess our models. But the main issue is how much this really matter? at how much $X\%$ difference in the performance that humans start to perceive the difference for example? This is very important in order to reach ML that actually matters in real life.

    \item The experimental protocol and scientific practices:

    \item Use of CNN instead of RNN for the style extraction (embedding) part: more flexible and faster, many off-the-shelf components to choose from (in order to build the network)
\end{itemize}
